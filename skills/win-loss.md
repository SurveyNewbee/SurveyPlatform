---
name: win-loss
description: |
  Diagnoses why B2B deals are won or lost by surveying decision-makers who recently completed complex purchase decisions, measuring decision criteria importance against competitive performance. Use when analyzing sales outcomes in B2B, high-consideration, or multi-stakeholder purchases with long sales cycles. Requires recent, completed decisions with known competitive alternatives - not suitable for general customer preference research or early-stage market exploration.
category: b2b_research
foundational: false
primary_use_case: Identify why deals are won or lost to improve sales strategy, messaging, and competitive positioning
secondary_applications:
  - Competitive intelligence and positioning analysis
  - Sales process optimization and training priorities
  - Product roadmap prioritization based on decision drivers
  - Price sensitivity and value perception diagnosis
commonly_combined_with:
  - message-test
  - pricing-study
  - buying-group-research
  - segmentation
requires:
  - screening
  - rating-scales
problem_frames_solved:
  - decline_diagnosis
  - performance_tracking
  - tradeoff_optimization
decision_stages:
  - measure
  - optimize
study_types:
  - b2b_research
  - competitive_intelligence
not_suitable_for:
  - General customer satisfaction or brand perception studies
  - Early-stage market research without defined competitive alternatives
  - Consumer purchases or simple transactional decisions
---


# Win–Loss Analysis Research Methodology

## Overview

Win–Loss research is a **post-decision diagnostic methodology** used to understand **why a company wins or loses deals**, how buyers evaluate options, and which factors most strongly influence final decisions. It is most commonly used in **B2B, high-consideration, or multi-stakeholder purchases**, where sales cycles are long and choices are complex.

This methodology prioritizes **decision reconstruction and comparative evaluation**. Surveys must capture what actually happened in real buying situations, not generic perceptions or aspirational criteria.

---

## Core Principles

- **Decision-based qualification**
  Only include respondents who were directly involved in a **recent, completed purchase decision**.

- **Reality over preference**
  Measure what influenced the actual outcome, not what respondents say “should” matter.

- **Competitive framing**
  Always evaluate the winning option relative to alternatives seriously considered.

- **Stakeholder awareness**
  Recognize that decisions may involve multiple influencers with different priorities.

- **Outcome neutrality**
  Use identical instruments for wins and losses to avoid bias.

- **Actionability**
  Insights must translate directly into changes in sales strategy, messaging, pricing, or product.

---

## Survey Design Requirements

### Question Structure

Surveys must follow this **mandatory structure**:

1. **Decision qualification**
2. **Purchase context**
3. **Decision outcome**
4. **Consideration set**
5. **Decision criteria**
6. **Comparative evaluation**
7. **Strengths and weaknesses**
8. **Process and experience**
9. **Future reconsideration**
10. **Firmographics / demographics**

#### Decision Qualification
- Qualify on:
  - Direct involvement in the decision
  - Decision completion
  - Recency (typically past 3–12 months)
- Disqualify advisory-only participants unless explicitly studying influencers.

#### Purchase Context
- Capture deal size, category, and use case.
- Identify purchase type (new buy, renewal, expansion).

#### Decision Outcome
- Explicitly identify whether the focal brand:
  - Won
  - Lost
  - Was shortlisted but not selected
- Route survey logic accordingly.

#### Consideration Set
- Capture all vendors seriously considered.
- Do not prompt unless necessary; allow open-ended listing first.

---

### Scale Design

- **Decision criteria importance**
  - Use 5-point importance scales.
  - Anchors: “Not at all important” to “Extremely important”.

- **Comparative performance**
  - Use 5-point relative performance scales.
  - Anchors: “Much worse than alternatives” to “Much better than alternatives”.

- **Satisfaction (wins only)**
  - Use 5-point satisfaction scales.
  - Anchor to delivery against expectations.

- **Reconsideration likelihood**
  - Use 5-point likelihood scales.
  - Ask of losses only.

- **Consistency rules**
  - Use identical scales for wins and losses.
  - Maintain consistent polarity throughout.

---

### Sample Questions

**Decision Outcome**
> Which of the following best describes the outcome of this decision?  
> - We selected \[FOCAL BRAND]  
> - We selected another provider  
> - No provider was selected  

**Decision Criteria Importance**
> How important was each of the following when making your final decision?

| Criterion | Not at all important | | | | Extremely important |
|---------|----------------------|-|-|-|-|
| Price | ☐ | ☐ | ☐ | ☐ | ☐ |
| Product capabilities | ☐ | ☐ | ☐ | ☐ | ☐ |
| Sales experience | ☐ | ☐ | ☐ | ☐ | ☐ |

**Comparative Performance**
> Compared to the other providers you considered, how did \[FOCAL BRAND] perform on each of the following?

---

## Common Mistakes to Avoid

- **Surveying the wrong respondents**
  *Wrong:* Asking general customers why they chose the brand  
  *Correct:* Survey only recent decision participants  
  *Why it matters:* Non-decision respondents speculate.

- **Leading loss framing**
  *Wrong:* “Why didn’t you choose us?”  
  *Correct:* Neutral outcome identification followed by diagnostics  
  *Why it matters:* Blame framing reduces honesty.

- **Ignoring competitors**
  *Wrong:* Evaluating the focal brand in isolation  
  *Correct:* Always measure relative to alternatives  
  *Why it matters:* Decisions are comparative.

- **Mixing hypothetical criteria**
  *Wrong:* “How important would this be next time?”  
  *Correct:* Focus on what mattered in the actual decision  
  *Why it matters:* Hypotheticals rewrite history.

- **Overloading criteria**
  *Wrong:* 25+ attributes  
  *Correct:* 8–12 decision-critical factors  
  *Why it matters:* Fatigue obscures true drivers.

---

## Analysis & Output Requirements

The survey must enable the following analyses:

- **Win vs. loss drivers**
  - Criteria importance × relative performance
  - Identification of true differentiators

- **Competitive positioning**
  - Where the brand wins and loses versus key competitors
  - White space opportunities

- **Sales experience impact**
  - Role of process, responsiveness, and trust
  - Separation of product vs. sales issues

- **Price diagnostics**
  - Price importance vs. price performance
  - Detection of value perception gaps

- **Future recovery**
  - Likelihood of reconsideration among losses
  - Conditions required to win next time

- **Sample size guidance**
  - Minimum n=75–100 wins and losses each
  - n=150+ per group recommended for robust diagnostics
  - Balance wins and losses where possible

- **Data structure**
  - Clear win/loss flag
  - Competitor identifiers
  - Criterion-level performance scores

---

## Integration with Other Methods

- **Message Testing**
  Win–loss findings inform which messages resonate in real decisions.

- **Pricing Studies**
  Clarifies whether price is a true barrier or a proxy for value.

- **Segmentation**
  Decision drivers can vary by segment, deal size, or use case.

- **Employee Enablement**
  Insights should directly inform sales training and enablement tools.

---

## Quality Checklist

- [ ] Respondents were directly involved in a recent decision  
- [ ] Decision outcome is clearly identified  
- [ ] Competitive set is captured accurately  
- [ ] Criteria importance and performance are measured separately  
- [ ] Wins and losses use identical instruments  
- [ ] Analysis isolates true drivers of outcome  
- [ ] Sales experience is evaluated alongside product  
- [ ] Sample size supports win/loss comparison  
- [ ] Outputs identify actionable changes  
- [ ] Results can be used by sales, marketing, and product teams
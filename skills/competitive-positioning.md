---
name: competitive-positioning
description: |
  Measures how brands are perceived relative to competitors on key attributes to map competitive positions, identify differentiation opportunities, and diagnose positioning strengths and weaknesses. Use when making positioning strategy decisions, evaluating competitive threats, identifying white-space opportunities, or understanding why a brand is winning or losing against specific competitors. Requires consistent attribute measurement across multiple brands using association or rating scales designed for perceptual mapping and correspondence analysis. Grounded in the principle that positioning exists in the customer's mind — not in what the brand claims, but in what buyers actually perceive relative to alternatives. Not suitable for categories with fewer than 3 meaningful competitors, brand identity or visual design research, or situations where the primary need is internal brand definition rather than competitive differentiation measurement.
category: brand_strategy
foundational: false
primary_use_case: Map how brands are perceived relative to competitors on key attributes to inform positioning strategy, competitive response, and differentiation
secondary_applications:
  - Identify positioning white-space opportunities in crowded markets
  - Diagnose competitive vulnerabilities and strengths
  - Evaluate positioning shift after campaign or repositioning efforts
  - Support merger/acquisition brand portfolio decisions
  - Inform messaging strategy by identifying ownable attribute territories
  - Benchmark new market entrants against established players
commonly_combined_with:
  - brand-tracking
  - customer-segmentation
  - market-share-tracking
  - concept-test
  - message-test
requires:
  - screening
  - demographics
problem_frames_solved:
  - experience_breakdown
  - decline_diagnosis
  - performance_tracking
  - tradeoff_optimization
decision_stages:
  - discover
  - define
  - measure
  - optimize
study_types:
  - brand_strategy
  - market_measurement
  - competitive_intelligence
not_suitable_for:
  - Categories with fewer than 3 meaningful competitors (insufficient map structure)
  - Brand identity or visual design research (use qualitative methods)
  - Internal brand definition without competitive reference (use brand architecture workshops)
  - Early-stage categories where consumers lack experience with the competitive set
  - Brand equity valuation for financial purposes (use brand valuation models)
---


# Competitive Positioning Research Methodology

## Overview

Competitive Positioning research measures **how brands are perceived relative to each other on attributes that matter to the market**. The output is a perceptual map — a visual representation of competitive positions — combined with diagnostic data that reveals where each brand is strong, weak, differentiated, or undifferentiated.

Positioning is fundamentally **relative, not absolute**. A brand is not "innovative" in isolation — it is "more innovative than Brand B but less innovative than Brand C." The survey must be designed to produce data that supports this relative interpretation: same attributes, same scales, same respondent base, measured across multiple brands simultaneously.

This methodology covers three complementary positioning measurement approaches:

| Approach | Best For | Output |
|----------|----------|--------|
| **Brand-attribute association** | Mapping which attributes each brand "owns" in consumers' minds | Association matrix, correspondence analysis map |
| **Brand-attribute rating** | Measuring strength of attribute perceptions with more granularity | Mean rating comparison, gap analysis, radar charts |
| **Importance-performance analysis (IPA)** | Connecting attribute perceptions to what actually drives choice | IPA quadrant map, priority matrix |

Most competitive positioning studies use brand-attribute association or rating as the core method, with importance-performance analysis as a strategic overlay. The choice depends on the number of brands, the number of attributes, and survey length constraints.

---

## Core Principles

- **Positioning is relative**
  Every perception is measured against alternatives. A brand cannot be "well-positioned" in a vacuum — only relative to what competitors offer and what customers value. The survey must measure the same attributes across all brands to enable comparison.

- **Perceptions, not claims**
  Positioning exists in the customer's mind, not in the brand's marketing materials. The survey measures what people actually believe about brands, which may differ dramatically from what brands intend to communicate. This gap between intended and perceived positioning is itself a critical diagnostic.

- **Attribute selection is strategy**
  The attributes included in the study define the competitive dimensions being assessed. Choosing the wrong attributes produces a map that is statistically valid but strategically irrelevant. Attribute selection must be grounded in category drivers, not brand aspirations.

- **Familiarity gates perception**
  Respondents cannot meaningfully rate brands they don't know. The survey must measure brand familiarity and either filter ratings to familiar brands or include an explicit "don't know" option. Forcing ratings of unfamiliar brands produces noise that distorts the perceptual map.

- **Differentiation is the goal, not favorability**
  The strategic value of positioning research is identifying what makes brands *different*, not just what makes them *good*. Attributes where all brands score similarly are competitively irrelevant regardless of how positive they are. The most valuable findings are attributes that discriminate between brands.

- **Consistency for tracking**
  If positioning is tracked over time, the attribute list, brand list, scale, and methodology must remain fixed. Changing any element breaks comparability and invalidates trend analysis. Treat the positioning battery like a measuring instrument — you don't recalibrate a thermometer between readings.

- **Segment-level analysis is essential**
  Aggregate perceptual maps obscure strategically important differences. A brand may appear undifferentiated overall but be strongly positioned among a high-value segment. Always analyse positioning by key segments.

---

## Survey Design Requirements

### Question Structure

Surveys must follow this **mandatory positioning sequence**:

1. **Category qualification and screening**
2. **Brand awareness and familiarity**
3. **Brand usage and consideration**
4. **Brand-attribute measurement (core positioning battery)**
5. **Attribute importance / choice driver measurement**
6. **Overall brand evaluation**
7. **Competitive preference and switching**
8. **Demographics / firmographics**

The positioning battery (Section 4) is the analytical core. Sections 2–3 provide the familiarity context and behavioral anchoring. Section 5 adds the strategic overlay that connects perceptions to what actually matters.

---

### Section 1: Category Qualification and Screening

Standard screener to qualify category participants who have meaningful exposure to the competitive set.

**Requirements:**
- Qualify based on category participation (purchase or usage) within a defined timeframe
- For positioning studies, the qualification window should be broad enough to capture experience with multiple brands (e.g., past 6–12 months rather than past 4 weeks)
- Include an awareness gate — respondents who have heard of fewer than 2 brands in the competitive set cannot contribute to meaningful positioning data

---

### Section 2: Brand Awareness and Familiarity

Measure which brands respondents know and how well they know them. This provides the familiarity filter for the positioning battery.

```
1. Unaided awareness
   When you think about [CATEGORY], which brands come to mind? Please list all brands you can think of.
   [Open-ended — coded to brand list in analysis]

2. Aided awareness
   Which of the following [CATEGORY] brands have you heard of, even if only by name? (Select all that apply)
   - [Brand A]
   - [Brand B]
   - [Brand C]
   - [Brand D]
   - [Brand E]
   - [Brand F]
   - Other (please specify)
   - None of these

3. Brand familiarity
   How familiar are you with each of the following brands?

   [MATRIX]
   Rows: [All brands from aided awareness list]
   Columns:
   - Very familiar — I know this brand well
   - Somewhat familiar — I know a fair amount about this brand
   - Slightly familiar — I've heard of it but don't know much
   - Not at all familiar — I've never heard of this brand
```

**Why familiarity matters for positioning:**
- Respondents rated as "Not at all familiar" or "Slightly familiar" should be excluded from attribute ratings for that brand (or their responses down-weighted)
- The familiarity question determines the effective base size for each brand's attribute ratings — smaller brands will have smaller rating bases
- Familiarity itself is a positioning dimension: being "well-known" vs. "niche/undiscovered" is a competitive characteristic

**Design rules:**
- Unaided awareness must come BEFORE aided awareness (no priming)
- The brand list must include all competitors being mapped plus the client brand
- Include 6–12 brands maximum — more than 12 creates excessive respondent burden in the attribute battery
- For tracking: fixed brand order across waves

---

### Section 3: Brand Usage and Consideration

Behavioral measures that anchor positioning perceptions to actual competitive behavior.

```
1. Brand consideration
   Which of the following brands would you consider [PURCHASING / USING] the next time you need [CATEGORY]? (Select all that apply)
   [Brand list + None of these]

2. Brand usage (recent)
   Which of the following brands have you [PURCHASED / USED] in the past [TIMEFRAME]? (Select all that apply)
   [Brand list + None of these]

3. Primary brand
   Which ONE brand do you [PURCHASE / USE] most often?
   [Single-select from brand list + "I don't have one I use most often"]
```

**Why this matters for positioning:**
- Positioning perceptions vary between users and non-users of a brand. Users typically rate their brand more favorably (usage-based halo effect). Analysing positioning separately for users vs. non-users reveals whether a brand's perceived strengths are real differentiation or merely familiarity bias.
- Consideration set data identifies which brands are in direct competition — not all aware brands are being actively evaluated.
- Primary brand identifies the "home brand" anchor for each respondent — their reference point when evaluating competitors.

---

### Section 4: Brand-Attribute Measurement (Core Positioning Battery)

This is the **analytical core** of the study. The battery measures how each brand is perceived on a set of competitively relevant attributes.

#### Choosing the Measurement Approach

**Option A: Brand-attribute association (pick-any)**

Respondents select which brands they associate with each attribute. Binary association (yes/no per brand).

```
Which of the following brands, if any, would you describe as [ATTRIBUTE]? (Select all that apply)

[Repeat for each attribute]

Brands:
- [Brand A]
- [Brand B]
- [Brand C]
- [Brand D]
- [Brand E]
- None of these
```

**When to use:** 6+ brands, 10+ attributes, shorter survey, correspondence analysis planned. This is the most efficient approach and produces clean data for perceptual mapping.

**Advantages:** Low respondent burden per item, works well with many brands, natural fit for correspondence analysis, avoids scale-use bias.

**Disadvantages:** Binary data loses granularity — a brand is either associated or not. Cannot measure *strength* of association.

---

**Option B: Brand-attribute rating (scaled)**

Respondents rate each brand on each attribute using a consistent scale.

```
How well does each of the following describe [BRAND A]?

[MATRIX]
Rows: [Attributes]
Columns:
- Describes very well
- Describes somewhat
- Does not describe
- Don't know this brand well enough to say
```

OR (5-point agreement version):

```
How much do you agree or disagree that [BRAND A] is [ATTRIBUTE]?

[MATRIX]
Rows: [Attributes]
Columns:
- Strongly agree
- Somewhat agree
- Neither agree nor disagree
- Somewhat disagree
- Strongly disagree
- Don't know this brand well enough to say
```

**When to use:** 3–5 brands, desire for granular strength measurement, gap analysis between specific brand pairs, tracking studies where detecting small shifts matters.

**Advantages:** Captures strength of perception (not just association), enables mean-score comparison and statistical testing of differences, more sensitive to change over time.

**Disadvantages:** Higher respondent burden (each brand × each attribute is a separate rating), prone to scale-use bias (some respondents rate everything high/low), practical limit of ~4–5 brands before fatigue degrades data.

---

**Option C: Hybrid — association screening with selective rating**

Use association (Option A) to identify which brands are associated with each attribute, then use rating (Option B) to measure strength for the client brand and 1–2 key competitors only.

**When to use:** 6+ brands in the market but only 2–3 need detailed competitive comparison. Efficient and deep where it matters.

---

#### Brand-per-page vs. Attribute-per-page Design

The matrix orientation affects data quality:

**Brand-per-page (respondent rates all attributes for one brand, then moves to next brand):**
- Better for: rating scales, fewer brands (3–5), when brand-level profiles are the primary output
- Risk: halo effect — respondents who like a brand rate it high on everything
- Mitigation: randomize attribute order within each brand page

**Attribute-per-page (respondent rates all brands on one attribute, then moves to next attribute):**
- Better for: association method, more brands (6+), when brand differentiation on specific attributes is the primary output
- Risk: primacy effects on brand list
- Mitigation: randomize brand order within each attribute page

**For association (pick-any) questions:** Always use attribute-per-page design. Each page asks "Which brands are [ATTRIBUTE]?" with all brands listed.

**For rating questions:** Brand-per-page is the standard for positioning studies with ≤5 brands. Beyond 5 brands, switch to association method.

---

#### Attribute Selection

Attribute selection is the most consequential design decision in a positioning study. The wrong attributes produce a map that is analytically sound but strategically irrelevant.

**Attribute selection principles:**

1. **Category-driven, not brand-driven**
   Attributes should represent the dimensions on which the CATEGORY is evaluated, not the dimensions on which one brand wishes to compete. Starting from brand strategy narrows the map to a self-serving view.

2. **Include functional AND emotional dimensions**
   Positioning operates on both rational evaluation (quality, value, convenience) and emotional association (trust, prestige, authenticity). A map built only on functional attributes misses half the competitive picture.

3. **Include table-stakes AND differentiators**
   Table-stakes attributes (e.g., "reliable", "good quality") may not differentiate but establish whether brands meet minimum expectations. Differentiating attributes (e.g., "innovative", "for people like me") reveal competitive advantage. Both are needed.

4. **Include positive AND negative/challenging attributes**
   Only measuring positive attributes produces uniformly favorable maps. Include attributes that capture weaknesses: "expensive", "hard to find", "old-fashioned", "complicated to use". These reveal vulnerabilities and competitive openings.

5. **Test for discrimination**
   If pre-testing or prior data is available, exclude attributes where all brands score within a few points of each other — they add survey length without analytical value. Every attribute should plausibly differentiate at least one brand from the pack.

6. **10–15 attributes is the practical range**
   Fewer than 8 produces an oversimplified map. More than 20 creates respondent fatigue and analytical noise. 10–15 is the sweet spot for most categories.

**Recommended attribute framework:**

| Dimension | Example Attributes | Purpose |
|-----------|-------------------|---------|
| **Quality / performance** | "High quality", "Reliable", "Superior performance" | Table-stakes assessment |
| **Value** | "Good value for money", "Worth the price", "Affordable" | Price-value positioning |
| **Innovation** | "Innovative", "Leading-edge", "Always improving" | Differentiation on newness |
| **Trust / credibility** | "Trustworthy", "A brand I can rely on", "Transparent" | Emotional foundation |
| **Relevance / fit** | "For people like me", "Understands my needs", "Modern" | Personal connection |
| **Premium / prestige** | "Premium quality", "Prestigious", "A brand to aspire to" | Aspirational positioning |
| **Accessibility** | "Easy to find", "Convenient", "Available where I shop" | Practical positioning |
| **Expertise / authority** | "Expert in the field", "Knowledgeable", "Specialist" | Authority positioning |
| **Ethics / responsibility** | "Environmentally responsible", "Ethical", "Socially conscious" | Values-based positioning |
| **Distinctiveness** | "Unique", "Different from other brands", "Stands out" | General differentiation |
| **Negative / challenging** | "Overpriced", "Old-fashioned", "Hard to use", "Nothing special" | Vulnerability detection |

**Category-specific attributes** should replace or supplement the generic framework above. For example:
- **Coffee:** "Bold flavor", "Smooth taste", "Ethically sourced", "Freshly roasted"
- **Software:** "Easy to integrate", "Scalable", "Good support", "Feature-rich"
- **Financial services:** "Secure", "Low fees", "Good mobile app", "Personalized service"

**Attribute wording rules:**
- Keep attributes short (2–4 words) — they appear in matrices and on map labels
- Use consumer language, not marketing jargon
- Each attribute should express a single dimension (no double-barreled attributes)
- Phrase as descriptors that complete the sentence "This brand is..." or "This brand has..."
- Maintain identical wording across waves in tracking studies

---

### Section 5: Attribute Importance / Choice Driver Measurement

Connect attribute perceptions to what actually drives purchase decisions. Without this, you know where brands sit on the map but not which positions matter.

**Option A: Importance rating**

```
How important are each of the following when choosing a [CATEGORY] brand?

[MATRIX]
Rows: [Same attributes as Section 4, randomized]
Columns:
- Extremely important
- Very important
- Moderately important
- Slightly important
- Not at all important
```

**Option B: MaxDiff (best-worst scaling) — recommended for stronger discrimination**

```
Of the following attributes, which is MOST important and which is LEAST important to you when choosing a [CATEGORY] brand?

[Show 4–5 attributes per task, 8–12 tasks total]

Task 1:
  ○ Most important    ○ Least important
  - High quality         ☐                    ☐
  - Good value           ☐                    ☐
  - Innovative           ☐                    ☐
  - Trustworthy          ☐                    ☐
  - Environmentally 
    responsible           ☐                    ☐
```

**Option C: Derived importance (no additional question)**

Derived importance uses statistical analysis (e.g., regression or Shapley values) to determine which attributes most strongly predict an overall outcome variable (overall brand preference, purchase intent, or NPS). No explicit importance question is needed — importance is inferred from the relationship between attribute ratings and the outcome.

**When to use each:**
- **Option A** when survey length is constrained and a simple directional read on importance is sufficient
- **Option B** when there are 8+ attributes and ceiling effects in importance ratings are a concern (everything rated "very important")
- **Option C** when the overall evaluation question (Section 6) is included and the analyst can perform multivariate analysis — this avoids the well-documented gap between stated and derived importance

**Why importance matters for positioning:**

Importance transforms the perceptual map from descriptive to prescriptive:
- An attribute where the brand leads but importance is low = wasted positioning
- An attribute where the brand trails but importance is high = critical vulnerability
- An attribute where no brand leads and importance is high = white-space opportunity

---

### Section 6: Overall Brand Evaluation

A global evaluation question for each brand provides the dependent variable for derived importance analysis and a summary metric for competitive comparison.

**Option A: Overall favorability**

```
Overall, how favorably do you view each of the following brands?

[MATRIX]
Rows: [Brands — show only those rated "somewhat familiar" or above in Section 2]
Columns:
- Very favorable
- Somewhat favorable
- Neither favorable nor unfavorable
- Somewhat unfavorable
- Very unfavorable
- Don't know enough to say
```

**Option B: Overall brand quality**

```
How would you rate the overall quality of each of the following brands?

[MATRIX]
Rows: [Brands]
Columns:
- Excellent
- Very good
- Good
- Fair
- Poor
- Don't know enough to say
```

**Option C: Net Promoter Score (for client brand users only)**

```
On a scale of 0 to 10, how likely are you to recommend [CLIENT BRAND] to a friend or colleague?
[0 = Not at all likely ... 10 = Extremely likely]
```

**Design rules:**
- Include "Don't know enough to say" to prevent forced ratings of unfamiliar brands
- Use the same scale for all brands — no asymmetric measurement
- Place AFTER the attribute battery — overall ratings informed by attribute-level thinking are more considered and stable than snap judgments

---

### Section 7: Competitive Preference and Switching

Capture direct competitive comparison data that supplements the attribute-level positioning analysis.

```
1. Competitive preference
   If [CATEGORY] brands were equally available and priced, which ONE brand would you most prefer to use?
   [Single-select from brand list + "No preference"]

2. Closest competitor identification
   Which ONE other brand is most similar to [PRIMARY BRAND from Section 3]?
   [Single-select from remaining brands + "None are similar"]

3. Competitive advantage (open-ended)
   What, if anything, makes [CLIENT BRAND] different from other [CATEGORY] brands?
   [Open-ended]

4. Competitive vulnerability (open-ended)
   What, if anything, would make you switch from [CLIENT BRAND] to another brand?
   [Open-ended — show only to client brand users]
```

**Why this matters:**
- Competitive preference reveals which brand "wins" when all other factors are equalized — a pure positioning metric
- Closest competitor identification maps perceived competitive proximity directly (supplements the statistical proximity from the perceptual map)
- Open-ended differentiation and vulnerability questions provide qualitative context that the quantitative map cannot — the language consumers use to describe differences is itself strategically valuable for messaging

---

### Section 8: Demographics / Firmographics

Standard profiling variables for segment-level positioning analysis.

**Consumer studies — required:**
- Age (bands)
- Gender
- Region / location
- Household income
- Education level
- Household composition

**B2B studies — required:**
- Company size (employees)
- Industry / sector
- Annual revenue (bands)
- Role / seniority

---

## Scale Design

- **Brand-attribute association (pick-any)**
  - Binary per brand: associated / not associated
  - "None of these" option required
  - Attribute-per-page orientation

- **Brand-attribute rating**
  - 3-point association: "Describes very well" / "Describes somewhat" / "Does not describe"
  - OR 5-point agreement: "Strongly agree" to "Strongly disagree"
  - Always include "Don't know this brand well enough to say"
  - Brand-per-page orientation for ≤5 brands

- **Attribute importance**
  - 5-point importance: "Extremely important" to "Not at all important"
  - OR MaxDiff for better discrimination (8+ attributes)

- **Overall brand evaluation**
  - 5-point favorability or quality scale
  - Include "Don't know enough to say"

- **Brand familiarity**
  - 4-point: "Very familiar" to "Not at all familiar"
  - Used as a filter for attribute ratings

- **Consistency rules**
  - Same attributes measured for ALL brands in the competitive set
  - Same scale used for all brands (no asymmetric measurement)
  - Same attribute wording across waves in tracking studies
  - "Don't know" always available for unfamiliar brands
  - Randomize attribute order within each brand (rating) or brand order within each attribute (association)

---

## Number of Brands: Design Guidelines

The number of brands significantly impacts survey design, respondent burden, and analytical approach:

| Brands | Recommended Approach | Survey Burden | Map Quality |
|--------|---------------------|---------------|-------------|
| 3–4 | Rating matrix (brand-per-page) | Low — all brands rated on all attributes | High granularity but sparse map |
| 5–6 | Rating matrix OR association | Moderate — rating approach reaching burden limit | Good balance of depth and breadth |
| 7–10 | Association (pick-any) recommended | Manageable with association; prohibitive with rating | Rich map structure |
| 11–15 | Association (pick-any) required | Acceptable with association only | Comprehensive map; may need attribute reduction |
| 16+ | Not recommended in a single study | Excessive regardless of method | Consider splitting into sub-category studies |

**When the client wants to map 10+ brands:**
- Use the association (pick-any) approach — it scales efficiently
- Consider reducing attributes to 10–12 to manage the grid size
- Apply familiarity filters — respondents only see brands they are at least "slightly familiar" with
- Accept that smaller brands will have smaller effective bases and wider confidence intervals on the map

---

## Common Mistakes to Avoid

- **Asymmetric brand measurement**
  *Wrong:* Measuring 15 attributes for the client brand and 8 for competitors
  *Correct:* Identical attributes measured for all brands in the competitive set
  *Why it matters:* Positioning is relative. If Brand A is measured on "innovative" but Brand B is not, you cannot determine their relative positions on innovation. The map requires complete data across all brands and attributes.

- **Omitting the familiarity gate**
  *Wrong:* Forcing all respondents to rate all brands on all attributes regardless of familiarity
  *Correct:* Measure familiarity first, then either filter (exclude unfamiliar brand ratings) or include "Don't know" and treat as missing data
  *Why it matters:* Respondents who don't know a brand will either skip (creating non-random missing data) or guess (creating noise that pulls the brand toward the map center — making it appear undifferentiated when it's actually unknown).

- **All positive attributes**
  *Wrong:* Measuring only desirable attributes: "high quality", "innovative", "trustworthy", "good value"
  *Correct:* Include challenging attributes: "expensive", "old-fashioned", "hard to find", "nothing special"
  *Why it matters:* All-positive attribute sets compress the map into one corner (all brands rated somewhat positively on everything). Negative and challenging attributes create the contrast that reveals genuine competitive separation.

- **Too many attributes, too few brands**
  *Wrong:* 25 attributes measured across 3 brands
  *Correct:* 10–15 attributes across 5–8 brands
  *Why it matters:* With few brands and many attributes, the perceptual map has more dimensions than data points — it overfits and produces unstable solutions. The ratio of brands to dimensions should be at least 3:1 for correspondence analysis.

- **Category-irrelevant attributes**
  *Wrong:* Including "innovative" for a commodity category where nobody chooses based on innovation
  *Correct:* Derive attributes from category purchase drivers, qualitative exploration, or prior U&A data
  *Why it matters:* Attributes that don't matter to the purchase decision produce statistically valid but strategically useless positioning data. The map accurately shows where brands sit — on dimensions nobody cares about.

- **Randomizing brand list in tracking studies**
  *Wrong:* Randomizing the brand order in the attribute battery each wave
  *Correct:* Fixed brand order across waves (randomize attribute order instead)
  *Why it matters:* In rating-scale approaches, brand position in the list produces small but systematic primacy/recency effects. These are consistent within a wave (so they don't bias relative positions) but if they change between waves, they create false shifts.

- **Interpreting the map center as "average"**
  *Wrong:* "Brand D is in the center of the map, so it's perceived as average on everything"
  *Correct:* The center may represent undifferentiated perception, low familiarity, or genuine mid-positioning. Diagnose which by examining base sizes, familiarity levels, and raw attribute scores.
  *Why it matters:* Low-familiarity brands and genuinely undifferentiated brands both land near the center for different reasons. The strategic response is completely different: one needs awareness, the other needs differentiation.

- **Ignoring segment-level maps**
  *Wrong:* Producing a single aggregate perceptual map and calling it done
  *Correct:* Generate segment-level maps (at minimum: users vs. non-users, demographic cuts, behavioral segments)
  *Why it matters:* A brand may appear undifferentiated in the aggregate but be strongly positioned among its target segment. Conversely, a brand may appear well-positioned overall because it's loved by a segment it's not targeting.

- **Confusing intended positioning with perceived positioning**
  *Wrong:* "Our brand is positioned as premium and innovative — the map confirms this"
  *Correct:* Compare the intended positioning (what the brand claims) against the perceived positioning (what consumers actually believe). The gap is the diagnostic.
  *Why it matters:* The whole point of positioning research is to measure reality against aspiration. Confirming what you already believe is a waste of research budget. The value is in the surprises.

- **No importance overlay**
  *Wrong:* Mapping positions without connecting them to what drives choice
  *Correct:* Overlay importance data to identify which positions matter, not just where brands sit
  *Why it matters:* A brand that "owns" an unimportant attribute is poorly positioned. A brand that owns an important attribute has competitive advantage. Without importance data, you can't tell which is which.

---

## Analysis & Output Requirements

### Perceptual Mapping

The primary analytical output is a perceptual map that visualizes competitive positions in 2D (or occasionally 3D) space.

**Correspondence analysis (for association data):**

Correspondence analysis (CA) is the standard technique for mapping brand-attribute association data. It reduces the brand × attribute matrix into a small number of dimensions that explain the maximum variance in associations.

```
Input: Brand × Attribute association matrix (% associating each brand with each attribute)

         Quality  Value  Innovative  Trust  Premium  Ethical  Modern
Brand A    72%    45%      58%       68%     62%      35%     55%
Brand B    55%    68%      32%       52%     28%      42%     30%
Brand C    48%    52%      65%       40%     45%      60%     68%
Brand D    62%    38%      42%       58%     55%      28%     42%
Brand E    35%    72%      25%       35%     18%      55%     22%

Output: 2D map where proximity indicates similar positioning
  - Brands close together are perceived similarly
  - Attributes close to a brand indicate that brand "owns" that attribute
  - Attributes and brands in the same map quadrant are associated
  - Variance explained by each dimension is reported (target: >60% in 2 dimensions)
```

**Principal components analysis / factor analysis (for rating data):**

When using rating scales rather than binary association, PCA or factor analysis reduces the attribute ratings into underlying dimensions, and brands are plotted on the resulting factor space.

```
Input: Brand × Attribute mean rating matrix

Output: Factor structure revealing underlying dimensions 
  (e.g., Factor 1 = "Quality/Premium" vs "Value/Accessible"; 
   Factor 2 = "Innovative/Modern" vs "Traditional/Established")

Brands plotted on the factor space based on their factor scores.
```

**Map interpretation guidelines:**
- Label each axis with the attributes that load most strongly on that dimension
- Report % variance explained by each dimension
- Mark the map center and note which brands are near it (undifferentiated or unfamiliar) vs. at the periphery (differentiated)
- Draw convex hulls or confidence ellipses around each brand's position if uncertainty is relevant
- Overlay attribute vectors showing direction of increasing association

### Brand-Attribute Comparison Grid

The comparison grid is the tabular complement to the perceptual map — it provides the exact numbers behind the visual.

```
Brand-Attribute Association Grid (% associating)
════════════════════════════════════════════════════════════════════
                   Brand A  Brand B  Brand C  Brand D  Brand E  Category
                                                                  Avg
────────────────────────────────────────────────────────────────────
High quality         72%      55%      48%      62%      35%      54%
Good value           45%      68%      52%      38%      72%      55%
Innovative           58%      32%      65%      42%      25%      44%
Trustworthy          68%      52%      40%      58%      35%      51%
Premium              62%      28%      45%      55%      18%      42%
Ethically sourced    35%      42%      60%      28%      55%      44%
Modern               55%      30%      68%      42%      22%      43%
Good value for money 42%      65%      48%      35%      70%      52%
For people like me   48%      38%      52%      40%      32%      42%
Easy to find         58%      62%      35%      55%      48%      52%
════════════════════════════════════════════════════════════════════

Index scores (brand % / category avg × 100):
Brand A on "High quality": 72/54 × 100 = 133 (33% above category average)
Brand E on "Premium": 18/42 × 100 = 43 (57% below category average)

Highlight cells where index > 120 (strength) or index < 80 (weakness)
```

### Importance-Performance Analysis (IPA)

The IPA quadrant combines attribute importance with brand performance to identify strategic priorities.

```
IPA Quadrant Map for [CLIENT BRAND]
═══════════════════════════════════════

                    HIGH IMPORTANCE
                         │
    ┌────────────────────┼────────────────────┐
    │                    │                    │
    │  QUADRANT II       │  QUADRANT I        │
    │  CONCENTRATE HERE  │  KEEP UP THE       │
    │                    │  GOOD WORK         │
    │  High importance,  │  High importance,  │
    │  low performance   │  high performance  │
    │  = Vulnerability   │  = Strength        │
    │                    │                    │
LOW ├────────────────────┼────────────────────┤ HIGH
PERF│                    │                    │ PERFORMANCE
    │  QUADRANT III      │  QUADRANT IV       │
    │  LOW PRIORITY      │  POSSIBLE          │
    │                    │  OVERKILL          │
    │  Low importance,   │  Low importance,   │
    │  low performance   │  high performance  │
    │  = Irrelevant      │  = Wasted effort   │
    │                    │                    │
    └────────────────────┼────────────────────┘
                         │
                    LOW IMPORTANCE

Where:
  Importance = from Section 5 (stated or derived)
  Performance = client brand's attribute score relative to competitive average
```

**Quadrant interpretation:**
- **Q1 (Keep up):** High importance, strong performance. Competitive advantage — protect these.
- **Q2 (Concentrate):** High importance, weak performance. Vulnerability — close these gaps or risk share loss.
- **Q3 (Low priority):** Low importance, weak performance. Not worth investing in.
- **Q4 (Possible overkill):** Low importance, strong performance. May be over-investing; consider reallocating resources.

### Competitive Gap Analysis

For specific brand pairs, calculate the gap on each attribute to identify competitive strengths and vulnerabilities.

```
Competitive Gap: Brand A vs. Brand C
═══════════════════════════════════════════════════
Attribute         Brand A  Brand C  Gap (A-C)  Direction
─────────────────────────────────────────────────────
High quality        72%      48%     +24 pp    A leads ✓
Innovative          58%      65%      -7 pp    C leads
Modern              55%      68%     -13 pp    C leads ✗
Trustworthy         68%      40%     +28 pp    A leads ✓✓
Premium             62%      45%     +17 pp    A leads ✓
Ethically sourced   35%      60%     -25 pp    C leads ✗✗
For people like me  48%      52%      -4 pp    Parity
═══════════════════════════════════════════════════

Key: ✓✓ = significant strength (>20 pp gap)
     ✓  = moderate strength (10-20 pp gap)
     ✗  = moderate weakness (10-20 pp gap)
     ✗✗ = significant weakness (>20 pp gap)
     Parity = <10 pp gap
```

### White-Space Analysis

Identify attribute positions that are important to consumers but not strongly owned by any brand.

```
White-Space Identification
═══════════════════════════════════════════════════════
Attribute           Importance    Highest Brand    Owning     White
                    Rank          Association      Brand      Space?
─────────────────────────────────────────────────────────
High quality          1              72%           Brand A     No
Good value            2              72%           Brand E     No
Trustworthy           3              68%           Brand A     No
Innovative            4              65%           Brand C     Partial
Ethically sourced     5              60%           Brand C     Partial
For people like me    6              52%           Brand C     Yes ✓
Modern                7              68%           Brand C     No
Easy to find          8              62%           Brand B     No
═══════════════════════════════════════════════════════

White-space criteria:
  - Importance rank in top 50% of attributes
  - No single brand >55% association (no clear owner)
  - Gap between #1 and #2 brand <15 pp (contested territory)
```

### Positioning Shift Analysis (For Tracking Studies)

When measured across waves, track how brand positions evolve:

```
Brand A Position Shift: Wave 1 → Wave 3
═══════════════════════════════════════════
Attribute        W1     W2     W3    Change   Sig?
──────────────────────────────────────────────
High quality     68%    70%    72%    +4 pp    No
Innovative       42%    48%    58%   +16 pp    Yes ✓
Modern           38%    45%    55%   +17 pp    Yes ✓
Premium          58%    60%    62%    +4 pp    No
Ethically sourced 30%   32%    35%   +5 pp    No
══════════════════════════════════════════════

Interpretation: Brand A has significantly strengthened its 
"Innovative" and "Modern" associations over 3 waves — consistent 
with the repositioning campaign launched between W1 and W2. 
Quality and premium positions remain stable (protected). 
Ethical positioning has not moved despite sustainability messaging.
```

### Sample Size Guidance

| Analysis | Minimum n | Recommended n |
|----------|-----------|---------------|
| Aggregate perceptual map (all brands) | 400 category users | 600+ |
| Per-brand attribute base (for rating approach) | 150 familiar with brand | 200+ |
| Per-brand attribute base (for association approach) | 200 familiar with brand | 300+ |
| Segment-level positioning | 150 per segment | 200+ per segment |
| Tracking: detect 5 pp shift in association | 400 per wave | 600+ per wave |
| Tracking: detect 10 pp shift in association | 200 per wave | 300+ per wave |

**Rules:**
- Effective base for each brand's attribute ratings is determined by familiarity, not total sample
- Small/niche brands may have effective bases of n=100–150 even with n=600 total — flag the wider confidence intervals
- For correspondence analysis, a minimum of 5 brands × 8 attributes is needed for a stable 2D map
- For tracking, same sample size each wave to maintain consistent precision

---

## Integration with Other Methods

- **Brand Tracking**
  Competitive positioning is often embedded as a module within brand health tracking. The attribute battery provides the "why" behind movements in brand awareness, consideration, and usage metrics. Rising consideration with stable positioning suggests improved salience; rising consideration with shifted positioning suggests the repositioning is working.

- **Customer Segmentation**
  Segment-level perceptual maps are among the most strategically valuable outputs in market research. Different segments may perceive the competitive landscape completely differently — revealing which brands are competitors in which segments and where positioning opportunities exist for each audience.

- **Market Share Tracking**
  Positioning data explains share movements. If Brand A gains share and its positioning on "innovation" and "value" has strengthened, you have a plausible causal chain. If share moves without any positioning shift, look for distribution, pricing, or promotional explanations instead.

- **Concept Testing**
  Before testing new concepts, the positioning map identifies the competitive space the concept must occupy. A concept positioned in crowded territory faces a harder path than one targeting a white-space. Post-concept test, check whether the concept would move the brand's position on the map toward the intended destination.

- **Message Testing**
  Positioning research identifies the attributes worth communicating. Message testing evaluates which executions most effectively communicate those attributes. The positioning map is the strategic input; message testing is the tactical validation.

- **Pricing Studies**
  Positioning on "premium" and "value" attributes directly connects to pricing strategy. A brand perceived as premium has more pricing power. A brand perceived as "good value" risks being undermined by price increases. The positioning-price connection is essential for revenue strategy.

---

## Deliverables Framework

### Primary Outputs

1. **Perceptual map** — 2D correspondence analysis or PCA map showing all brands and attributes
2. **Brand-attribute comparison grid** — full association/rating matrix with index scores
3. **Competitive gap analysis** — pairwise attribute comparison between client brand and key competitors
4. **IPA quadrant** — importance-performance analysis identifying strategic priorities for client brand
5. **White-space analysis** — high-importance attributes not strongly owned by any brand

### Secondary Outputs

6. **Segment-level perceptual maps** — positioning by demographic, behavioral, or attitudinal segments
7. **Positioning shift tracking** — wave-on-wave attribute changes (for tracking studies)
8. **Closest competitor analysis** — which brands are perceived as most similar/substitutable
9. **User vs. non-user positioning comparison** — how perceptions differ between brand users and non-users
10. **Open-ended differentiation themes** — coded qualitative data on perceived brand differences

### Strategic Recommendations

11. **Positioning territory recommendation** — which attributes the client brand should own, based on importance, current position, competitive landscape, and feasibility
12. **Competitive vulnerability assessment** — where each competitor is weak and could be challenged
13. **Messaging priority** — which attributes to emphasize in communications, based on importance, current ownership, and white-space
14. **Repositioning risk assessment** — if a positioning shift is contemplated, which current strengths might be at risk

---

## Quality Checklist

### Survey Design
- [ ] Brand awareness and familiarity measured before attribute battery
- [ ] Familiarity gate applied — unfamiliar brands not force-rated (or "Don't know" available)
- [ ] Same attributes measured for ALL brands in competitive set (no asymmetry)
- [ ] Attributes include functional, emotional, positive, and negative/challenging dimensions
- [ ] 10–15 attributes covering the category's competitive dimensions
- [ ] Measurement approach matched to number of brands (association for 6+, rating for ≤5)
- [ ] Attribute importance or choice drivers measured (stated or derived)
- [ ] Overall brand evaluation included as dependent variable for derived importance
- [ ] Brand usage and consideration captured for user vs. non-user analysis
- [ ] Open-ended differentiation question included for qualitative context
- [ ] For tracking: attribute list, brand list, scale, and wording fixed across waves

### Analysis
- [ ] Perceptual map produced using appropriate technique (CA for association, PCA for ratings)
- [ ] Variance explained by map dimensions is reported (target >60% in 2D)
- [ ] Map axes labeled with the attributes that define each dimension
- [ ] Brand-attribute comparison grid produced with index scores
- [ ] IPA quadrant produced connecting importance to performance
- [ ] White-space analysis identifies unowned but important attribute positions
- [ ] Competitive gap analysis completed for client brand vs. key competitors
- [ ] Segment-level maps produced for strategically relevant segments
- [ ] User vs. non-user analysis reveals familiarity bias vs. genuine differentiation
- [ ] Statistical significance tested for attribute differences between brands
- [ ] Effective base sizes reported for each brand (accounting for familiarity filter)

### Deliverables
- [ ] Positioning territory recommendation is specific and evidence-based
- [ ] White-space opportunities are validated by both importance and lack of ownership
- [ ] Competitive vulnerabilities are identified with supporting data
- [ ] Recommendations distinguish between what the brand currently owns vs. what it should aspire to own
- [ ] If tracking, positioning shifts are tested for significance and connected to in-market activity